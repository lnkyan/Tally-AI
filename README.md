# Tally-AI
利用chatGPT的[函数调用](https://platform.openai.com/docs/guides/gpt/function-calling)功能实现的自然语言记账小管家

该项目代码80%是由[Claude 2](https://claude.ai/)生成出来。调试和前端UI调整由人工完成

## 快速开始
### 环境需求
- Node.js v16+
- OpenAI的API Key，支持使用`gpt-3.5-turbo`模型

### 安装
```
npm install
```

### 配置
复制`.env.example`创建`.env`文件，在其中填写OpenAI的API Key等信息。  
也可以直接把这些变量配置为环境变量

### 运行
```
npm start
```
服务会运行在 [http://localhost:3000](http://localhost:3000)

## 项目结构
```
├── src               源码目录
│   ├── controllers   控制器层 
│   ├── services      业务层
│   ├── models        数据层
├── data              数据库目录
└── public            静态资源目录
```

## 经验总结
- Claude 2 确实有GPT4的水平，连续对话几十条后，仍然能够清楚记得讨论过的所有源码，并且记住的是多次修改后的最新版
- AI生成的代码会倾向直接堆在一个文件里，不太考虑架构设计。但只要一句话，它就能又好又快得完成模块提取，并修改关联代码。因此利用AI来辅助学习和理解架构问题非常方便。它知道正确的做法，并且能够用当前正在讨论中的项目举例，非常容易理解
- 各种开源库在互联网上的资料一定是版本越老资料越多。所以训练出的AI会倾向使用老版本，在当下有些代码已经无法运行了。特别是UI库这种变化频繁的三方库。因此**AI更适合生成偏后端的代码**
- chatGPT的函数调用功能可以把常规的输入框+按钮式的交互转化为聊天的形态。但它毕竟是一个语言模型，在生成日期、金额类数值型的函数参数时，特别容易出现错误。比如当用户输入“昨天”时，ChatGPT可能会在`year`参数上生成一个2021或者2022；而对于一个“2元”的消费，它又可能在以分为单位的`amount`参数上生成一个`-2`。**对于语言模型来说，它特别难以理解`现在`的概念**
- 一开始，我按照传统的后端项目，通过网络接收到用户的指令，在controller层完成数据验证、组装等，然后分发给下层。但接入AI后，用户的调用请求会从`aiService`模块发出来，直接调用到下层的各服务。而AI生成的数据格式千奇百怪，必须做大量的校验与纠正。这导致原本controller层的工作全被塞进`aiService`了

## 许可
该项目使用 MIT 许可证。